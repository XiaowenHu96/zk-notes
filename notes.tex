\documentclass[10pt]{article}

\usepackage[urlcolor=blue, colorlinks=true]{hyperref}
\usepackage{forest}
\usepackage{tikz}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\newtheorem{lemma}{Lemma}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{remark*}{Remark}
\newtheorem{remark}{Remark}
\newtheorem{sublemma}{Lemma}[lemma]
\newcommand{\FFamily}{\mathbb{F}^{(\leq d)}_p[X]}
\newcommand{\FField}{\mathbb{F}_p}
\newcommand{\MyOmega}{e^{2\pi ik/n}}
\newcommand{\GOne}{\mathbb{G}_1}
\newcommand{\GTwo}{\mathbb{G}_2}
\newcommand{\GT}{\mathbb{G}_T}
\newcommand{\HL}[1]{\textcolor{red}{#1}}

\begin{document}
\section*{ZK notes}
\begin{description}
    \item Some keynotes made while learning about ZK, SNARK, STARK and ZK-VM.
    \item Lectures: \href{https://www.youtube.com/playlist?
        list=PLj80z0cJm8QErn3akRcqvxUsyXWC81OGq}{Youtube Playlist}
\end{description}

\section{SNARK}
SNARK is not necessary ZK and can be quite different from STARK and ZK-VM. But
it should be a good starting ground to understand some basic concept.

\subsection{Polynomial Commitment Scheme (PCS)}
A PCS is a functional commitment for the family $\mathcal{F} \in \FFamily$.
A prover commits to univariate polynomial $f$ in $\FFamily$ and can later prove
to the verifier that $v = f(u)$ for public $u, v \in \FField$.

Some examples PCS (here we focus on KZG'10):
\begin{enumerate}
    \item Bulletproof (elliptic curves, but verification is $O(d)$)
    \item KZG'10 (trusted setup, bilinear), Dory'20 (bilinear)
    \item Dark'20 (groups of unknown order)
    \item Hash (FRI)
\end{enumerate}

\subsection{KZG'10}
Set cyclic group $\mathbb{G} = \{0, G, 2 \cdot G, 3 \cdot G, \ldots, (p-1) \cdot
G\}$ of order $p$.

\subsubsection*{Setup algorithm}
\begin{enumerate}
    \item Sample random $\alpha \in \FField$.
    \item $pp = (H_0 = G, H_1 = \alpha \cdot G, \ldots, H_d = \alpha^d \cdot G)
        \in \mathbb{G}^{d+1}$.
    \item \textbf{delete $\alpha$} (i.e., A trusted setup)
\end{enumerate}

\subsubsection*{Commitment}
In short: $commit(pp, f) \rightarrow com_{f}$, where $com_{f} = f(\alpha) \cdot G \in
\mathbb{G}$.\footnote{This is not a hiding commitment} \\

\begin{remark*}
    As a result, the committed message is extremely short (an
    element $G$) regardless how large our polynomial is.
\end{remark*}

But $\alpha$ is deleted during trusted setup, how does prover compute
$f(\alpha)$?\\
Observe:
\begin{description}
    \item $\Rightarrow f(X) = f_0 + f_1X + \ldots + f_dX^d $
    \item $\Rightarrow f(\alpha) \cdot G = f_0 \cdot G + f_1 \cdot \alpha \cdot G 
        + \ldots + f_d \cdot \alpha^d \cdot G $
    \item $\Rightarrow f(\alpha) \cdot G = f_0 \cdot H_0 + f_1 \cdot H_1 + \ldots + f_d
        \cdot H_d $
\end{description}

\subsubsection*{Evaluation}
How to prove $f(u) = v$?\\ 

First Observe:
\begin{enumerate}
\item If $f(u) = v \Longleftrightarrow u$ is a root of polynomial
    $\hat{f}(X) = f(X) - v$.
\item If $u$ is a root of $\hat{f}(X) \Longleftrightarrow \hat{f}(X)$  is divisible
    by $(x - u)$.
\item $f(u) = v \Longleftrightarrow \exists q \in \FFamily$ s.t. $q(X)(X-u)=f(X)-v$
    
\end{enumerate}

\begin{description}
    \item The prover then computes quotient polynomial $q(X) = (f(X) - v) / (X - u)$
        and sends $com_q$ to verifier.
    \item The verifier accepts if $(\alpha - u) \cdot com_q = com_f - v \cdot G$.
\end{description}

LHS:
\begin{description}
    \item $\Rightarrow (\alpha - u) \cdot com_q$
    \item $\Rightarrow (\alpha - u) \cdot (q_0 H_0 + q_1 H_1 + \ldots + q_d H_d)$
    \item $\Rightarrow (\alpha - u) \cdot (q_0 G + q_1 \alpha G + \ldots + q_d \alpha^d G)$
    \item $\Rightarrow commit(pp, (X-u)q(X))$
\end{description}
RHS is similar. \footnote{Important: verifier does not actually need to know
about $\alpha$. The \emph{pairing} is used here to allow verifier to compute
$(\alpha - u) * com_q$ with only $G$ and $H_1$}
\begin{remark*}
    The verification work only take constant time, regardless of the degree of
    the polynomial.
\end{remark*}

\subsubsection*{Extension}
\begin{enumerate}
    \item KZG for k-variant polynomial (PST'13)
    \item Batch proofs: prove a batch of commitments in a single step.
\end{enumerate}


\subsection{A Useful Observation}
A Useful and important observation.

For $0 \neq f \in \FFamily$.
Let $r$ be a random point $r \leftarrow \FField$, the probability 
$pr[f(r) = 0] = d/p$.\footnote{Given $f$ has at most $d$ roots and $p$ elements}

For large enough $p$ and reasonable $d$, e.g., $p \approx 2^{256}$ and $d \leq
2^{40}$, $d/p$ is negligible.

\begin{lemma}\label{observation1}
    for $r \leftarrow \FField$, if $f(r) = 0$, we can conclude $f$ is
    identically zero w.h.p.\footnote{Also holds for multivariate polynomial,
    see SZDL lemma.}
\end{lemma}

Further more, with the same settings. \\
\begin{lemma}\label{observation2}
Let $f, g \in \FFamily$. For $r \leftarrow \FField$, if
$f(r) = g(r)$ then $f = g$.
\end{lemma}
\begin{description}
    \item $\Rightarrow f(r) - g(r) = 0$
    \item $\Rightarrow$ Let $h = f - g$, from Lemma~\ref{observation1}, $h$ is
        identical zero w.h.p.
    \item $\Rightarrow f = g$, w.h.p
\end{description}

\subsection{Zero Test On H}
One of the (and the simplest) poly-IOP tasks that the verifier would like the
prover to do.

\begin{description}
\item Let $\omega \in \FField$ be a primitive $k$-th root of unity (such
    that $\omega^{k} = 1$ and  $\omega^n \neq 1$ for $n < k$).
\item Set $H = \{1, \omega, \omega^2, \ldots, \omega^{k-1}\} \in
    \FField$. 
\item Let polynomial $f \in \FFamily$.
\end{description}

A zero test is a test from verifier to prover to prove that: \textbf{$f$ is
identically zero on set $H$.}

\begin{lemma}\label{zero-test}
    $f$ is zero on $H$ iff $f(X)$ is divisible by $X^k - 1$.
\end{lemma}
\begin{enumerate}
    \item The prover can compute the quotient polynomial $q(X) = f(X) /
        (X^k - 1)$. and send the commitment of $q$ to the verifier.
    \item The verifier then choose random $r \in \FField$ and ask prover
        to open $f(X)$ and $q(X)$ at r.
    \item The verifier then accepts the test if $f(r) = q(r) \cdot (r^k - 1)$
\end{enumerate}
As mentioned in Lemma~\ref{observation2}, two polynomials that agree on a random point $r$
has a high probability that the two polynomials are identical. 
Therefore, the above implies $f(X) = q(X)(X^k - 1)$. This proves $f(X)$ is
indeed divisible by $X^k - 1$, hence from Lemma~\ref{zero-test}, $f$ is
identical on $H$.

\subsection{Interpolate Polynomial}
Plonk.

\subsubsection{Compile a circuit into a computation trace}
\begin{minipage}{.5\textwidth}
\begin{forest}
[$(x_1 + x_2)(x_2 + w_1)$
    [Gate2: $\times$, edge={<-}, edge label={node[midway,left]{77}}
    [Gate0: $+$, edge={<-}, edge label={node[midway,left]{11}}
        [$x_1$, edge={<-}, edge label={node[midway,left]{5}}]
        [$x_2$, edge={<-}, name=n1, edge label={node[midway,right]{6}}]
    ]
    [Gate1: $+$, edge={<-},name=n2, edge label={node[midway,right]{7}}
        [$w_1$, edge={<-}, edge label={node[midway,right]{1}}]
    ]
    ]
]
\draw[->] (n1) -- node[midway,right]{6} (n2);
\end{forest}
\end{minipage}
\begin{minipage}{.5\textwidth}
\begin{tabular}{l|r|r|r}
    inputs: & 5 & 6 & 1 \\
    \hline
    & left & right & out \\
    \hline
    Gate0 & 5 & 6 & 11 \\
    Gate1 & 6 & 1 & 7 \\
    Gate2 & 11 & 7 & 77 \\
    \hline
\end{tabular}
\end{minipage}\\
\subsubsection{Encoding the trace as polynomial}
\begin{description}
    \item $C \leftarrow$: total \# of gates
    \item $I \leftarrow |I_x| + |I_w|$: \# inputs to circuit
    \item $d \leftarrow 3|C| + |I| = 12$ for our example. ($3$ since each gate has $3$ inputs).
    \item $H \leftarrow \{1, \omega, \ldots, \omega^{(d-1)}\}$ 
\end{description}

The goal here is to interpolate a polynomial $P$ that encodes the computation
trace. To achieve that, we want to
\begin{enumerate}
    \item let $P$ encodes all inputs, such that $P(\omega^{-j}) =$ inputs \# j
        for all $j = 1, \ldots, |I|$.
    \item let $P$ encodes all wires, such that $\forall l = 0, \ldots, |C|-1$:
        \begin{enumerate}
            \item $P(\omega^{3l}) = $ left input of gate \# $l$.
            \item $P(\omega^{3l+1}) = $ right input of gate \# $l$.
            \item $P(\omega^{3l+2}) = $ output of gate \# $l$.
        \end{enumerate}
\end{enumerate}
This results in $12$ constraints for $P$, which means there exists a $P$ with
degree at most $11$ that satisfies all the constraints. \HL{Prover can then 
constructs $P$ using Fast Fourier Transform in time $O(d\log d)$, which
I don't know how yet.}

\subsubsection{Prove that encoding is correct}
There are four things to prove.\\

\textbf{Inputs are correctly encoded.}\\
Both prover and verifier takes input $x$ and interpolate a polynomial $v(X) \in
\FFamily$ that satisfies $\forall j = 1, \ldots, |I_x|: v(\omega^{-j}) = $input \#j.

\HL{From the slides, it says construction takes time linear to the size of $x$, shouldn't
it still be using FFT and the time is actually $O(n \log n)$?}. 

Then prover just proves that $P(y) - v(y) = 0\ \ \forall y \in H_{inp}$ where
$H_{inp}$ is all the input points, i.e., $\{\omega^{-1}, \ldots,
\omega^{-|I_x|}\}$. This can be done using zero-test.

\textbf{Gates evaluations are correctly encoded.}\\
Interpolate selector polynomial $S(X) \in \FFamily$ such that $\forall l =
0,\ldots, |C| - 1$:
\begin{enumerate}
    \item $S(\omega^{3l}) = 1$ if gate $l$ is addition
    \item $S(\omega^{3l}) = 0$ if gate $l$ is multiplication
\end{enumerate}
Observe $\forall y \in H_{gates} = \{1, \omega^{3}, \omega^{6}, \ldots,
\omega^{3(|C|-1)}\}$:
$$
S(y) \cdot [P(y) + P(\omega y)] + (1 - S(y))\cdot P(y)\cdot P(\omega y) =
P(\omega^{2}y)
$$
When $S(y) = 1$, which means a gate is addition gate, and $[P(y) + P(\omega y)]$
encodes the two inputs of that gate, which equals to $P(\omega^{2}y)$ (where $\omega^2y$ encodes the output of the circuit). 
At the same time, since the gate is addition, the right operand $((1 -
S(y))\cdot \ldots)$ must evaluated to zero. The same goes for when $S(y) = 0$,
i.e., multiplication gate.

Overall, another zero-test on $H_{gates}$.

\textbf{Wirings are encoded correctly.}\\
For example, the input $6$ flows to right input of Gate0 and left input of
Gate1, we need to prove that does data flows (wiring) are encoded correctly.
For our examples, the equivalent constraints are:
$$
  \begin{cases}
    P(\omega^{-2}) = P(\omega^1) = P(\omega^3) \\
    P(\omega^{-1}) = P(\omega^0) \\
    P(\omega^{2}) = P(\omega^6) \\
    P(\omega^{3}) = P(\omega^4) \\
  \end{cases}       
$$
To do so, define a rotation polynomial $W : H \rightarrow H$ such that:
$$
  \begin{cases}
      W(\omega^{-2}, \omega^{1}, \omega^{3}) = (\omega^{3}, \omega^{-2}, \omega^{1})\\
      W(\omega^{-1}, \omega^{0}) = (\omega^{0}, \omega^{1}) \\
      \ldots \\
  \end{cases}       
$$
\begin{lemma}
    $\forall y \in H: P(y) = P(W(y)) \Rightarrow $ wiring constraints are
    satisfied.
\end{lemma}
\HL{Since W has degree of $d$ and P has degree of $d$, the verification can takes
quadratic time. The trick here is to use prod-check (another IOP check) to
reduce it to linear complexity. Not sure how to yet, another time. :P}

\textbf{Outputs are encoded correctly (is zero).}\\
Just let prover to open $P$ at the output of the final gate.

\section{STARK}
This follows the tutorial at
\href{https://aszepieniec.github.io/stark-anatomy}{here}


\subsection{Extended Euclidean Algorithm}
Refresh myself with the Extended Euclidean algorithm...

Extended Euclidean algorithm is an extension of the Euclidean algorithm, in
addition to computing the greatest common divisor of two integer $a$ and $b$,
it also gives $x$ and $y$ such that:
$$
ax + by = gcd(a, b)
$$

Recall the standard Euclidean algorithm in recursive form: $gcd(a, b) = gcd(b,
a \mod b)$, stops at $gcd(r, 0)$ and returns $r$. 

The Extended Euclidean Algorithm works the same, but keeps the quotient at
each iterations.
$$
\begin{aligned}
    r_0 = a & \ \  s_0 = 1 & t_0 = 0\\
    r_1 = b & \ \  s_1 = 0 & t_1 = 1\\
            & \ldots &  \\
           & r_i = r_{i-2} - q_{i-1} r_{i-1} \\
           & s_i = s_{i-2} - q_{i-1} s_{i-1}  \\
           & t_i = t_{i-2} - q_{i-1} t_{i-1}\\
\end{aligned}
$$

The EEA is useful as it defines the inverse of an element under $\FField$.
Give an element $x \in \FField$, the inverse of $x$ is therefore $a$:
\begin{description}
    \item $\Rightarrow gcd(x, p) = 1$
    \item $\Rightarrow ax + bp \equiv 1 \mod p$
    \item $\Rightarrow ax \equiv 1 \mod p$
\end{description}

\subsection{Lagrange Interpolation}
Refresh myself with Lagrange Interpolation.

The Lagrange Interpolation returns a polynomial of lowest degree that pass
through a set of points $D$.

As an example, consider three points $(3, 1), (4, 2), (7, -3)$. The algorithm
first construct three polynomial such that each polynomial $f_i$ go through $(x_i,
1)$ for the $i^{th}$ point in $D$ and $(x_j, 0)\ \forall j \neq i$.
This is extremely easy:

$$
\begin{cases}
    f_1(x) = \sfrac{1}{4}(x-4)(x-7) \\
    f_2(x) = \sfrac{1}{3}(x-3)(x-7) \\
    f_3(x) = \sfrac{1}{12}(x-3)(x-4) \\
\end{cases}
$$


Finally, just scale each $f_i$ so when $x = x_i \Longrightarrow y = y_i$, and let $p =
\sum_{i}f_i$
$$
p(X) = f_1(X) + 2 * f_2(X) + -3 * f_3(X)
$$

We can also prove the resulting polynomial $p(X)$ is the unique polynomial of
degree $(n-1)$ that go through those points, by contridiciton.

Assuming the opposite, let $q(X)$ be another polynomial of degree $n-1$ that
statistifes points $d \in D$. Since $q(X) \neq p(X)$, $r(X) = q(X) - p(X)$ is
not a zero polynomial and $degree(r) \leq (n-1)$. However, we know for
points $d \in D$, $r(X) = q(X) - p(X) = 0$, which means $degree(r) = n$,
therefore contridiciton.

\subsection{FRI}
\emph{Fast Reed-Solomon IOP of Proximity}.

FRI is a protocol between a prover and a verifier, which establishes that a
given codeword belongs to a polynomial of low degree – low meaning at most $p$
times the length of the codeword. 

\subsection{Fast Fourier Transform \& Polynomials}
Consider some simple polynomial algorithms.
\begin{itemize}
    \item Multiplying two polynomial of coefficient representation. $O(n^2)$.
    \item Coefficient representation to point-value representation. $O(n^2)$ as
        you need to evaluate $n+1$ points for a $n$-degree polynomial.
    \item Lagrange. $O(n^2)$ as mentioned in previous section.
\end{itemize}

With Fast Fourier Transform, it is possible to perform above
algorithms in $O(n\log n)$.

\subsection{Point-value Representation and Polynomial Multiplication}
Consider two polynomials of degree of $n-1$:
\[
\begin{aligned}
    A(X) &= a_0 + a_1x + a_2x^2 + \ldots + a_{n-1}x^{n-1} \\
    B(X) &= b_0 + b_1x + b_2x^2 + \ldots + b_{n-1}x^{n-1} \\
\end{aligned}
\]

Each polynomial can be represented by a list of coefficients of size $n$, $a =
(a_0, a_1, \ldots, a_{n-1})$. The multiplication is represented by $a
* b$, which takes $O(n^2)$.

Another way of representing a polynomial is through the idea that a polynomial
of degree $n-1$ is uniquely defined by $n+1$ points. So
\[
    A(X) = \{(x_0, A(x_0)), (x_1, A(x_1)), \ldots, (x_{n-1}, A(x_{n-1}))\}
\]

Multiplication of two polynomial can then be defined by multiplication of those
uniquely defined points, $C(X) = A(X)B(X)$:
\[
    C(X) = \{(x_0, A(x_0)B(x_0)), (x_1, A(x_1)B(x_1)), \ldots, (x_{n-1}, A(x_{n-1})B(x_{n-1}))\}
\]
The only catch here is that $C(X)$ is a polynomial of degree $2n-2$, so we
actually need to find more points ($2n-1$) on $A$ and $B$ in order to uniquely define $C$.
However, the complexity of the multiplication drop from $O(n^2)$ to $O(n)$.

\subsubsection{Goals}
Obviously if we simply choosing arbitrary $2n$ points on the polynomial then
this will take us $O(n)$ time for each point and ends up with $O(n^2)$
complexity again. The remark here is that by choosing a specific set of points
with Fast Fourier Transform, we can find the point-value representation in
just $O(n\log n)$.

\subsubsection{Complex Root of Unity}
A number $z \in \mathbb{C}$ is an \emph{$n^{th}$ root of unity if $z^n = 1$}.
The pricipal $n$th root of unity is $\omega_n = e^{\frac{2\pi i}{n}}$.
The intution here is that $e^{\frac{2\pi i}{n}}$ is a function that rotates
as a cycle (through $i$) and has radius of $1$ (through $e^{2\pi}$), $n$ then
defines a radians of the rotation. The magic value $\omega_n^n$ then defines
each full rotation.

\begin{lemma}\label{cancel-lemma}
    For integer $n\geq 0$, $k \geq 0$, $d \geq 0$, $\omega^{dk}_{dn} = \omega^{k}_{n}$.
\end{lemma}
$$\omega^{dk}_{dn} = (e^{\frac{2\pi i}{dn}})^{dk} = (e^{\frac{2dk\pi i}{dn}}) = 
(e^{\frac{2k\pi i}{n}}) = \omega_n^{k}
$$

\begin{lemma}\label{halving-lemma}
    If $n$ is even, then squares of the $n$th complex unity root is equal to
    the $n/2$ of the $n/2$th complex unity root.
\end{lemma}
$$
\omega^2_{n} = (e^{\frac{4\pi i}{n}}) = (e^{\frac{2\pi i}{n/2}}) = \omega_{\frac{n}{2}}
$$
This extends to the $k$th power of the $n$th complex unity root:
$$
(\omega^k_{n})^2 = (\omega^{2k}_{n}) = \omega^{k}_{\frac{n}{2}}
$$
\begin{lemma}\label{summation-lemma}
    If $n \geq 1$ and $k$ is not divisible by $n$:
    $$
    \sum_{j=0}^{n-1}(\omega^{k}_n)^j = 0
    $$
Proof:
\end{lemma}
\[
    \sum_{j=0}^{n-1}(\omega^{k}_n)^j = \frac{1 - \omega^{kn}_n}{1 -\omega^{k}_n}
    = \frac{1 - (\omega^{n}_n)^k}{1 -\omega^{k}_n}
    = \frac{1 - 1^k}{1 -\omega^{k}_n}
    = 0
\]
This is true as $k$ is not divisible by $n$ hence $\omega^{k}_n \neq 1$.

\subsubsection{Discrete Fourier Transform}
Let $a = (a_0, a_1, \ldots, a_{n-1})$ be a coefficient representation of
polynomial $A$, define $\hat{a} = (\hat{a}_0, \hat{a}_1, \ldots,
\hat{a}_{n-1})$ where:
\[
    \hat{a}_k = \sum^{n-1}_{j=0}{a_j\omega^{kj}_n} 
\]

The remark is shown by considering value of polynomial $A$ at point
$\omega^k_n$.
\[
    A(\omega^k_n) = \sum^{n-1}_{j=0}{a_j\omega^{kj}_n} = \hat{a}_k.
\]

Each $A(\omega^k_n)$ still takes $O(n)$ to compute, there are still a lot of missing pieces, wait...

\subsubsection{Fast Fourier Transform}
FFT is an efficient algorithm of computing the above sequence using a
divide-and-conquer approach.

Assuming n is a power of $2$, in addition to $A(X)$, we define two other
polynomials:
\[
\begin{aligned}
    A_e(X) &= a_0 + a_2x + a_4x^2 + \ldots + a_{n-2}x^{\frac{n-2}{2}} \\
    A_o(X) &= a_1 + a_3x^1 + a_5x^{2} \ldots + a_{n-1}x^{\frac{n-2}{2}} \\
\end{aligned}
\]
We can then represent $A$ by:
\[
    A(X) = A_e(X^2) + XA_o(X^2)
\]
The problem of evaluating $A$ at $(\omega^0_n, \omega^1_n, \ldots, \omega^{n-1}_n)$
is reduced to:
\begin{enumerate}
    \item Compute $A_e$ and $A_o$ at $((\omega^0_n)^2, (\omega^1_n)^2, \ldots,
        (\omega^{n-1}_n)^2)$
    \item Combine the result
\end{enumerate}
Wait, but $A_e$ and $A_0$ only have degree $n/2$ and cannot be used to
evaluated the full sequence. But consider $d \leq \frac{n}{2}$:
\footnote{\HL{The slides specifically refers to halving
lemma~\ref{halving-lemma}, but I don't see how the lemma is necessary here to
get the conclusion.}}
\[
    (\omega^{d}_n)^2 = \omega^{2d}_{n}\omega^{n}_{n} = \omega^{2d+n}_{n} =
    (\omega^{d + \frac{n}{2}}_n)^2
\]
Therefore, calculating the first halves of the sequence give us the result in the second
halves. This also explains in the earlier section why only providing $n$ points
is enough to calculate polynomial $C$ of degree $2n-2$.

\subsubsection{Inverse of FFT}
Consider again the discrete Fourier Transform problem, which is a linear map from
$\mathbb{C}^n \rightarrow \mathbb{C}^n$. We can therefore write it as a matrix
multiplication:
\[
\begin{bmatrix}
    1      & 1              & 1                 & \ldots & 1\\
    1      & \omega_n       & \omega^2_n        & \ldots & \omega^{n-1}_n \\
    \vdots & \vdots         & \vdots            & \ddots & \vdots \\
    1      & \omega^{n-1}_n & \omega^{2(n-1)}_n & \ldots & \omega^{(n-1)^2}_n
\end{bmatrix}
\begin{bmatrix} a_0\\ a_1\\ \vdots\\ a_{n-1} \end{bmatrix}
=
\begin{bmatrix} \hat{a}_0\\ \hat{a}_1\\ \vdots\\ \hat{a}_{n-1} \end{bmatrix}
\]

Denote each matrix as $M_n(\omega_n)$, $A_n$ and $\hat{A}_n$ . $M_n(\omega_n)$ has a
special name in linear algebra, called \emph{Vandermonde Matrix}.
To get from $\hat{A}_0$ and $M_n(\omega_n)$ to $A_0$, we simply need to find
the inverse of $M_n(\omega_n)$, which turns out to be very simple.

\begin{lemma}
    For $n \geq 1$, $M_n(\omega_n)$ is invertible and
    \[
        M_n(\omega_n)^{-1} = \frac{1}{n}M_n(\omega^{-1}_n)
    \]
\end{lemma}

\emph{Proof:}\\
The $(i, j)$ entry of $M_n(\omega_n)$ is $(\omega^{i}_n)^j = \omega^{ij}_n$. 
The entry $(i, j)$ entry of $\frac{{1}}{n}M_n(\omega^{-1}_n)$ is
$\frac{1}{n}(\omega^{-i}_n)^j = \omega^{-ij}_n$. 
Hence, the $(i, j)$ entyry of the product of the two matrix is:
\[
    \frac{1}{n}\sum^{n-1}_{k=0}\omega^{ik}_n\omega^{-jk}_n = 
    \frac{1}{n}\sum^{n-1}_{k=0}\omega^{k(i - j)}_n=
    \frac{1}{n}\sum^{n-1}_{k=0}{(\omega^{(i - j)}_n)}^k
\]
if $j = i$, the sum is $n$, so the product evaluate to $1$. If $i \neq j$, the
sum must be $0$ from Lemma~\ref{summation-lemma}.

\begin{remark}
    Hence we can calculate $\hat{A} \cdot \frac{1}{n}M_n(\omega^{-1}_n)$ with
    FFT and get $A$. This enable Interpolation on primitive roots in logarithm
    time.
\end{remark}

\subsubsection{Q}
It seems like as long as $\omega_n$ statistifes that only $\omega^n_n = 1$ we
can get the same conclusion, not sure why the primitive root is used here (as
an example?). As well as some other lemmas... E.g., I don't get why halving
lemma is necessary to get the final conclusion, it just uses basic exponent
rules.

\section{Finite Fields}
Basic concept of finite field, for future references.

\subsection{Groups}
A group is a set of elements $G = \{a, b, c, \ldots\}$ and an operator
$\oplus$ such that
\begin{enumerate}
    \item Closure: $\forall a, b \in G: a \oplus b \in G$
    \item Associative $\forall a, b, c \in G: (a \oplus b) \oplus c = a \oplus
        (b \oplus c)\in G$
    \item Identity: $\exists 0 \in G, \forall a \in G: a \oplus 0 = a$
    \item Inverse: $\forall a \in G, \exists b \in G: a \oplus b = 0$, simply
        denote $b = -a$.
    \item Permutation: $\forall a \in G: a \oplus G = \{a \oplus b\ \vert\ b \in G\} =
        G$, in another word, this gives us a different permutation of $G$.
\end{enumerate}
In addition, if $\forall a, b \in G: a \oplus b = b \oplus a$, $G$ is called
\emph{abelian}.

Note: Often, the operation is called multiplication, presented by $\times$, and
identity is written as $1$, inverse is written with $a^{-1}$.

\subsection{Cyclic Groups}
A \emph{finite cyclic group} is a finite group $G$ with a \emph{generator}
element $g$ such that $G = \{g, g \oplus g, g \oplus g \oplus g, \ldots\}$

Since $g$ generates $G$, this must includes the identity element $0$. 
Therefore, we must have $ig = 0$ for some $i$. Let $k$ be the smallest $i$
such that $kg = 0$, we must have $ng \neq 0$ for $1 \leq n \leq k - 1$.
For each element $ng$ with $1 \leq n \leq k - 1$, we have:
\begin{description}
    \item $kg \neq 0$
    \item $\Longrightarrow kg + ng \neq ng$
    \item $\Longrightarrow (k + n)g \neq ng$
\end{description}
Therefore, all elements in $G$ are different.

\subsection{Subgroups}
A subgroup $S$ of a group $G$ is a subset of $G$ such that $\forall a,b \in S:
a \oplus b \in S$. Therefore, the subgroup must contain the identity element in
$G$ and all the inverse of each element in $S$. A subgroup is also a group.
If $G$ is abelian, then the subgroup is abelian. The inverse is not necessary
true.

\subsection{\HL{TBD}}

\section{Elliptic Curve}
Slowly connecting elliptic curve, pairing and KZG commitments.
It is hard to plot elliptic curve in latex, so figure would be omitted here.
I might add figure in later editing.
First part followed from
\href{https://andrea.corbellini.name/2015/05/17/elliptic-curve-cryptography-a-gentle-introduction/}{here}.

\subsection{Group Law for Elliptic Curve}
We can define a group over elliptic curve.
\begin{itemize}
    \item the elements of the group are the points of an elliptic curve
    \item the identity element is the point at infinity 0
    \item the inverse of a point is the one symmetric about the x-axis
    \item given three aligned points, $P, Q, R$, their sum is $P + Q + R = 0$.
\end{itemize}
Immediately, we have $P + (Q + R) = (P + Q) + R = R + (P + Q) = 0$, both
associative and commutative rules are satisfied, hence an \emph{abelian} group.

\subsection{Geometric Addition}
Given this is an abelian group, we have $P + Q = -R$. So we can draw a line
across $P, Q, R$, the symmetric point of $R$ gives us the result $-R$.
Consider some corner cases:
\begin{enumerate}
    \item What if $P = 0$ or $Q = 0$? Given $0$ is defined as identity
        element, we have $0 + P = P$.
    \item What if $P = -Q$? I.e., the line is vertical and only pass two
        points. Given the definition of inverse, we have $P + Q = P + (-P) =
        0$.
    \item What if $P = Q$? Imagine a point $Q'$ move toward $P$, as $Q' \approx
        P$ , we have a line that is tangent to the curve, hence we say $P + P =
        -R$, where $R$ is the point that intersect with the tangent line.  
    \item What if $P \neq Q$ but there is no third point and the line is not
        vertical? This is similar to the previous point, where line defined by
        $P, Q$ is tangent to the curve. Assuming $P$ is the tangent point, we
        then have $P + P = -Q$.
\end{enumerate}

\subsection{Algebraic Addition}
This is entirely by me, not sure if my conclusion is right (audit it please),
the details are omitted in the origin post.

Consider two points $P = (x_P, y_P), Q = (x_Q, y_Q)$, how to find the third
point $R = (x_R, y_R)$ such that three are points aligned (assuming exists).

We know line pass three points have the form:
\[
    y = y_Q + m(x - x_Q)
\]
or:
\[
    y = y_P + m(x - x_P)
\]
Hence $y_R = y_Q + m(x_R - x_Q)$. Next finding $x_R$. Given curve of form $y^2 =
x^3 + Ax + B$, we have:
\[
    x^3 + Ax + B - (m(x - x_Q) + y_Q)^2 = 0
\]
for $x$ taking $x_Q,x_P$ and $x_R$. Expanding it:
\begin{description}
    \item $\Longrightarrow x^3 + Ax + B - (mx - mx_Q + y_Q)(mx - mx_Q + y_Q)$
    \item $\Longrightarrow x^3 + Ax + B - m^2x^2 + m^2xx_Q - mxy_Q + m^2xx_Q
        - m^2{x^2_Q} + mx_Qy_Q - mxy_Q + mx_Qy_Q - {y^2_Q}$
    \item $\Longrightarrow x^3 + (-m^2)x^2 + (A + 2m^2x_Q - 2my_Q)x + (B -
        m^2x^2_Q + mx_Qy_Q - mx_Qy_Q - y^2_Q)$
\end{description}
Looks complicated, but from \emph{Vieta's formulas}, we have the sum of roots:
\[
\sum_{r_i} = -\frac{a_{n-1}}{a_n}
\]
where $a_n$ is the $n^{th}$ coefficient. So $x_Q + x_P + x_R = m^2$, and we have
\[
    x_R = m^2 - x_Q - x_P
\]
with slop $m$
\[
    m = \frac{y_P - y_Q}{x_P - x_Q}
\]

Note, this also works on tangency point ($Q = P$). It's just that the slop $m$ needs to
taken by first derivatives:
\[
    m = \frac{3x^2_P+a}{2y_P}
\]

\subsection{Scalar Multiplication}
We define scalar multiplication $nP$:
\[
    nP = P + P + P \ldots P
\]
There exists simple logarithm algorithm for computing $nP$.

\subsection{Elliptic Curve over $\FField$}
When define over $\FField$, we have a set of points:
\[
    \{(x, y) \in \FField^2\ \vert\ y^2 \equiv x^3 + ax + b \mod p\} \cup \{0\}
\]

The \emph{order} of a group is the cardinality of the set of points. This can
be done using the \emph{Schoof's Algorithm}.

\HL{The core of the discrete logarithm is that: given $P$ and $Q$, it is "hard" to find $k$ such that $P = Qk$}.
\subsubsection{Point addition and algebraic sum}
The definition is almost the same, except we define three points are aligned if
there exists line $y \equiv ax + b \mod p$ that pass through all points. If you
can imagine, this line would wrap around the panels.
\begin{itemize}
    \item $Q + 0 = 0 + Q$.
    \item Given $Q = (x_Q, y_Q)$, $-Q = (x_Q, -y_Q \mod p)$
    \item $P + (-P) = 0$
\end{itemize}

The equations for calculating the third points given two points is exactly the
same, except taking the module of $p$.
\begin{itemize}
    \item $x_R = m^2 - x_P - x_Q \mod p$
    \item $y_R = y_P + m(x_R - x_P) \mod p$
    \item $m = (y_P - y_Q)(x_P - x_Q)^{-1} \mod p$ if $P \neq Q \mod p$
    \item otherwise, $m = (3x^2_P + a)(2y_P)^{-1} \mod p$
\end{itemize}

\subsubsection{Cyclic Subgroup}
Taking a point $P$ from the curve, the set of multiplicative of $P$ is closed
and forms a cyclic subgroup. $P$ is also called a \emph{generator} or a \emph{base}.
The order of such group (I.e., the order of $P$) is defined by the smallest
positive integer $n$ such that $nP = 0$, so brute force takes at least $O(n)$.
However, from \emph{Lagrange theorem}, which state that the order of subgroup must
be a divisor of the parent group.
Therefore, we can improve the algorithm: 
\begin{enumerate}
    \item Calculate order of the curve $N$ by Schoof's algorithm.
    \item Find all divisor of $N$
    \item For all divisor, try $nP$, the smallest $n$ such that $nP=0$ is the
        order of $P$.
\end{enumerate}

\subsubsection{Finding base point}
In some applications, we want to find a group of higher order. So instead of
starting from a base point $P$, we would start by finding all divisor of $N$, taking a
high divisor ($n$) to be the subgroup order, and work in reverse to find the generator
of that subgroup.

Note Lagrange theorem implies $h = N/n$ is always an integer (since $n$ must be
a divisor). The number $h$ is called \emph{cofactor}.

Consider for any point $P$ on the curve, we must have $NP = 0$, hence $n(hP) =
0$.
Now suppose $n$ is a prime number:
\begin{enumerate}
    \item Calculate order $N$ of the elliptic curve.
    \item Choose a $n$ we want to use as our subgroup order, but $n$ has to be a prime number.
    \item Compute cofactor $h$ by $N / n$.
    \item Choose a random point $P$ on the curve.
    \item Compute $G = hP$, if $G = 0$, go back to step $4$, otherwise, we
        have found the generator.
\end{enumerate}
The reason of why $n$ must be prime is because: if it is not, $P$ could have an
order that is actually a divisor of $n$.

\HL{This is interesting, I wonder whether special curve needs to be crafted so
that finding $P$ would not be so hard (a group with prime order or order with
only few divisor?).}

\subsubsection{Encryption with ECDH}
Since encryption is not our main concern, I'll just use an example to quickly
finish off this chapter.

A \emph{private key} is $d$, which is a random integer taken from the divisor of the
subgroup order $N$.
A \emph{public key} is the point $H=dG$, where $G$ is the base of the subgroup.

\begin{enumerate}
    \item Alice and Bob exchange their public key $H_A = d_AG$ and $H_B = d_BG$
        ($G$ can be shared, public information).
    \item Alice calculate $S_A = d_AH_B$ and Bob calculates $S_B = d_BH_A$, you
        can see $S_A = d_A(d_B)G = d_B(d_A)G = S_B$
\end{enumerate}

\section{Connecting Pairing With KZG}
\HL{This section still missing tons of detail}
\begin{enumerate}
    \item \href{https://hackmd.io/@gnark/kzg-bls24}{Yet another curve, but THE
            curve for your KZG!}
    \item
            \href{https://dankradfeist.de/ethereum/2020/06/16/kate-polynomial-commitments.html}{KZG
            polynomial commitments}
        \item \href{https://vitalik.ca/general/2017/01/14/exploring_ecp.html}{Exploring Elliptic Curve Pairings }
        \item \href{https://hackmd.io/@benjaminion/bls12-381}{BLS12-381 For The Rest Of Us}
\end{enumerate}

\subsection{Pairing}
A pairing is a bilinear map:
\[
    e: \mathbb{G}_1 \times \mathbb{G}_2 \rightarrow \mathbb{G}_T
\]
where
\begin{itemize}
    \item $\mathbb{G}_1$ and $\mathbb{G}_2$ are groups of order $r$ defined
        over elliptic curves with generator $G_1$ and $G_2$. 
    \item $\mathbb{G}_T$ is also a group over a \emph{finite field extension}.
\end{itemize}
In particular, $\mathbb{G}_1$ is usually defined over curve $E(\FField)$, and
$\mathbb{G}_2$ and $\mathbb{G}_T$ are defined over $E(\mathbb{F}_{p^k})$
\HL{TODO: Example with BLS12-381}.

The function $e$ has the following property:
\begin{enumerate}
    \item $e(r \times m, n) = r \times e(m, n)$
    \item $e(m, r \times n) = e(m, r) \times r$
\end{enumerate}

\HL{Almost certain it is wrong:}\\
For paring purpose on elliptic curve over finite field, we can conclude :
\begin{description}
    \item $e(r \times P, d \times Q)$
    \item $\Longrightarrow r \times e(P, d \times Q)$
    \item $\Longrightarrow r \times e(P, Q) \times d$
    \item $\Longrightarrow r \times d \times e(P, Q)$
    \item $\Longrightarrow e(P, Q)^{rd}$ \HL{something is missing here}
\end{description}
\HL{Many references omit what exactly is the function $e$ here. Looking at
some code examples and the post blow, I believe it is using either \emph{Tate Paring} or \emph{Weil Paring}}\\
\href{References}{https://crypto.stanford.edu/pbc/notes/ep/}

\subsection{KZG commitment}
\subsubsection{Single Polynomial Single Point}
Let $p(x)$ be the polynomial we want to commit
\begin{enumerate}
    \item setup secret $\tau$, sample randomly from $\FField$.
    \item Prove and verifier share $G_1$, $G_2$, $pk = \tau^iG_1$ and $vk = \tau G_2$
    \item Verifier receive commitment ${cm}_p = \sum_{i=0}p_i \cdot \tau^iG_1$ 
    \item Verifier send requests $open(p, y, z)$: to prove $p(z) = y$.
    \item Prover compute $q(x) = \frac{p(x) - y}{x-z}$ and send commitment
        ${cm}_q$.
    \item Verifier compute $P_z = zG_2$ and $P_y = yG_1$ and check 
        $e({cm}_q, vk-P_z) = e({cm}_p-P_y, G_2)$.
\end{enumerate}
For convince, we write $cm_{p} = \sum_{i=0}p_i \cdot \tau^iG_1 = p(\tau)$, same
goes for ${cm}_q$.\\
To see the correctness:
\[
\begin{aligned}
    e({cm}_q, vk-P_z) &= e({cm}_p-P_y, G_2)\\
    e(\sum_{i=0}q_i \cdot \tau^iG_1, \tau G_2-z G_2) &= e({cm}_p =
    \sum_{i=0}(p_i \cdot \tau^iG_1)-yG_1, G_2)\\
    e(G_1, G_2)^{q(\tau)(\tau - z)} &= e(G_1,G_2)^{p(\tau)-y}\\
    \mathbb{X}^{q(\tau)(\tau - z)}_{\mathbb{G}_T} &= \mathbb{X}^{p(\tau) - y}_{\mathbb{G}_T}
\end{aligned}
\]

\subsubsection{Single Polynomial Multiple Points}
Continue from above, now the request is a set of points $open(p, \{y_i\}, \{z_i\})$.
\begin{enumerate}
    \item Prover interpolate $I(x)$ such that $I(x)$ pass through $\{(z_i, y_i)\}$
        and $Z(x)$ such that $Z(x)$ is a zerofier on $\{z_i\}$.
    \item Prover compute $q(x) = \frac{p(x) - I(x)}{Z(x)}$
    \item Note: since $I(x)$ is the interpolation, $p(x) - I(x)$ equals to zero at
        $\{z_i\}$ therefore is divisible by $(x - z_i)$.
    \item Verifier compute $commit_{\mathbb{G}_2}(Z(x)) =
        cm_{Z_{\mathbb{G}_2}}$, $P_y = \sum_i{(y_i\cdot\tau^{i}G_1)} = cm_{I}$
        \HL{Here for the frist time we have a commitment under $\mathbb{G}_2$. Is it possible to avoid committing on G2?}
        \footnote{Also, does $P_y$ have to be calculated by the verifier. Can prover
        trick the verifier if they construct $P_y$ instead?}
\end{enumerate}
Remark here is that only one pairing is needed.
To see the correctness:
\[
\begin{aligned}
    e({cm}_q, cm_{Z_{\mathbb{G}_2}}) &= e({cm}_p-{cm}_I, G_2)\\
    e(\sum_{i}q_i \tau^iG_1, \sum_i{z_i \tau^i G_2}) 
                   &= e(\sum_{i}(p_i \cdot \tau^iG_1)-
                   \sum_i{(y_i\cdot\tau^{i}G_1)}, G_2)\\
    e(G_1, G_2)^{q(\tau)Z(\tau)} &= e(G_1,G_2)^{p(\tau)-I(\tau)}\\
    \mathbb{X}^{q(\tau)Z(\tau)}_{\mathbb{G}_T} &= \mathbb{X}^{p(\tau)-I(\tau)}_{\mathbb{G}_T}
\end{aligned}
\]

\subsubsection{Single Polynomial Multiple Points (But only on $\mathbb{G}_1$)}
The above method requires committing the zerofier over $\GTwo{}$.
There is an alternative method which only requires commitment over $\GOne$.
Which is by treating it as a special case of multiple polynomials with
multiple points. See below.


\subsubsection{Multiple Polynomials Single Point}
Given we have a set of polynomials = $\{P_i(x)\}$, how to verify 
$P_i(z) = y_i$ for some $z$ and $\{y_i\}$?

\begin{enumerate}
    \item Prover commits $cm_{p_i}$ for each $P_i$ .
    \item Prover computes and commits $Q(x) = \sum_i{\frac{P_i(X) - y_i}{X-z}}$
    \item Easy to see we should have $Q(x) * (x-z) = \sum_i{(P_i(X) - y_i)}$
\end{enumerate}
\[
\begin{aligned}
    e({cm}_q, vk - zG_2) &= e(\sum({cm}_{p_i})-\sum_i{(y_i G_1)}, G_2)\\
    e({cm}_q, \tau G_2 - zG_2) &= e(\sum\sum_i(p_i\tau^i G_1)
                            -\sum_i{(y_i G_1)}, G_2)\\
    e({cm}_q, \tau G_2 - zG_2) &= e(G1\cdot (\sum\sum_i{(p_i\tau^i)} - \sum_i{y_i}), G_2)\\
    e(G_1, G_2)^{q(\tau)(\tau - z)} &= e(G_1,G_2)^{\sum{(p_i(\tau)-y_i)}}\\
    \mathbb{X}^{q(\tau)(\tau - z)}_{\mathbb{G}_T} &= \mathbb{X}^{\sum{(p_i(\tau)-y_i)}}_{\mathbb{G}_T}
\end{aligned}
\]
\newpage
\subsubsection{Multiple Polynomials Multiple Points}
Given a set of points $\{z_{i}\}$, where each point correspond to a set of polynomials
$\{P_{ij}(x)\}$, how to prove each point is correctly opened at their
corresponded polynomials?

For each point $z_i$, let the expected value be $y_{ij}$.
Construct $Q_i(X) = \sum_j\frac{P_{ij}(X) - y_{ij}}{X-z_i}$.
% Observe that when taking $X = z_i$, polynomial would results in zero.

Now consider:
\begin{description}
    \item $Q_i(X) = {\sum_j\frac{P_{ij}(X) - y_ij}{X-z_i}}$
    \item $\sum_i(x-z_i) Q_i(X) = \sum_{i,j} P_{ij}(X) - y_{ij}$
\end{description}
However, I personally failed to construct the left-hand side, where a
multiplication exists in a summation. PLONK has a nice solution for that.

\[
\begin{aligned}
    e(\sum{(cm_{P_i} - G_1 y_i)} + \sum{(cm_{Q_i} z_i)}, G_2) &= e(\sum{cm_{Q_i}}, vk)\\
    e(\sum{(cm_{P_i} - G_1 y_i)} + \sum{(cm_{Q_i} z_i)}, G_2) \cdot e(-\sum{cm_{Q_i}}, vk) &= 1 \\
    e(\sum{(cm_{P_i} - G_1 y_i)} + \sum{(cm_{Q_i} z_i)} - \tau \cdot \sum{cm_{Q_i}\tau}, G_2) &= 1 \\
    e(\sum{(cm_{P_i} - G_1 y_i)} + \sum{(cm_{Q_i} (z_i-\tau))}, G_2) &= 1 \\
    e(\sum{(cm_{P_i} - G_1 y_i)} + \sum{(cm_{Q_i} (z_i-\tau))}, G_2) &= 1 \\
    e(\sum{(cm_{P_i} - G_1 y_i)} - \sum{(cm_{Q_i} (\tau - z_i))}, G_2) &= 1 \\
    e(G_1, G_2)^{\sum{(\tau(P_i - y_i) - \tau(Q_i)\tau(x-z))}} &= 1 \\
    e(G_1, G_2)^0 &= 1\\
\end{aligned}
\]

\subsubsection{Permutation Argument}
Given domain over $D=\{1, \ldots, \omega^{N-1}\}$ and two
polynomial $F$ and $Q$, how to prove their evaluation over domain $D$, $F(D)$
and $Q(D)$ are permutation of each other?

Key observation is that, two sets $\{a_i\}$ and $\{b_i\}$ are equal iff (with
few exceptions) $\prod_i\{a_i + \gamma\} = \prod_i\{b_i + \gamma\}$ for some
random $\gamma$.

Define sequence $r_i =
r_{i-1}\frac{F(\omega^{i-1}+\gamma)}{G(\omega^{i-1}+\gamma)}$ 
and define $r_1 = \frac{F(1)+\gamma}{G(1)+\gamma}$.
Clearly $r_{n} = \frac{\prod_iF(\omega^{i}) + \gamma}{\prod_iG(\omega^{i}) +
\gamma} = 1$.
If prover interpolates the sequence $r$ over domain $D$, we have $R(X)$ where
$R(\omega^{N-1}) = 1$.
Therefore, we have to prove
\begin{enumerate}
    \item $R(\omega^{N-1}) = 1$.
    \item $R(X)$ is constructed correctly.
\end{enumerate}
We first discuss how to prove $2$.

The prover has to prove, for $i \in D$:
\[
R(\omega^i)\cdot(G(\omega^{i}) + \gamma) = R(\omega^{i-1})\cdot (F(\omega^{i}) + \gamma)
\]
Note, one cannot directly perform pairing on the above equation,
since the above equation only holds for $i \in D$.
However verifier can choose to perform opening on every point on $i\in D$. But
 that contradicts to our purpose of having a fast verification process (we
 could have just opened on $f$ and $g$ on $i \in D$).
Therefore, a more clever method:

Observe:
\[
R(\omega\cdot X)\cdot(G(\omega\cdot X) + \gamma) - R(X)\cdot (F(\omega\cdot X) + \gamma)
\]
is divisible by $T = (x^N - 1)$.\HL{I don't see how. Is it obvious?}

Therefore, we can choose some random sample $z \in F$ and perform openings and
verify:
\[
    \frac{R(z \omega)\cdot ((G(\omega) + \gamma)) - R(z)\cdot(F(\omega z) + \gamma)}{(z^N - 1)} = Q(z)
\] 

Finally, we discuss a small trick
on proving the first claim. A usual way of proving $R(\omega^{N - 1})=1$  is by performing a
single open protocol. But to further push the performance limit, prover can use
a trick to force the correctness of the claim.

Notice when proving $2$, we need to do open protocol on $R$.
What if in the protocol, we enforce an implicit rule says that: whenever
verifier wants to open on $R$, instead of opening on $R$, prover should always
open on $R'(X) = R(X)(X-\omega^{N-1}) + 1$. Notice how $R'$ is constructed so
that it \emph{must} have $R'(\omega^{N-1}) = 1$.

Imagine if prover does not follow this rule, then the ill-constructed $R'$ will be
detected during the process of proving the second claim (point opening will
fail). And if the prover follow this rule, then the first claim is free.
Brilliant!

The actual protocol works out the above trick in reverse.
The prove commits $R$ by committing $R' = \frac{R(X)-1}{X-\omega^{N-1}}$.
And whenever verifier needs to open a point at $R(z)$, it opens at $R'(z)$ and
get the result by computing $(R'(z) (z-\omega^{N-1}) + 1)$.

% Here is an attempt trying to figure out why the polynomial can be divided by
% $x^N - 1$.
% We know polynomial has solution on $i \in D$, therefore we know it is divisible
% by $x - 1$. 
% \[
%     (x-1)(x^{n-1} + x^{n-2} + \ldots + 1) = (x^N - 1)
% \]

\end{document}
